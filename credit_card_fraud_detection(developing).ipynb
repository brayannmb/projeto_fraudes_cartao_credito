{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fcb246",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "Credit card fraud has been a big problem in the last few years, especially during the pandemic. We needed to buy everything online in this period such as food, medicine, clothe, book, and other. As a result, the criminals saw many opportunities to commit different crimes. Phishing was one of the crimes that had a growth. It's about stealing the user's data through calls, emails, and messages. In these social media, criminals send messages passing by financial companies to convince the users to answer with their data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d143f31",
   "metadata": {},
   "source": [
    "<center><img width=\"60%\" src=\"https://github.com/brayannmb/Data-Science/blob/main/credit_card_fraud/images/banner_credit_card.png?raw=true\"\n",
    "></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084d4f8",
   "metadata": {},
   "source": [
    "## Obtaining the Data\n",
    "\n",
    "Using data collected from Kaggle, we'll build a Machine Learning model that is capable of predicting fraudulent transactions. Beyond this, it will help the financial companies to minimize the problems with clients.\n",
    "\n",
    "This dataset contains 284807 lines and 31 columns. It was the result of the PCA method that reduced the dimensionality of a dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa75e2fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12544/3456308998.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#obtaining the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.dropbox.com/s/b44o3t3ehmnx2b7/creditcard.csv?dl=1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;31m# open URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    609\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[1;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"method\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         return IOArgs(\n\u001b[0;32m    318\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\braya\\appdata\\local\\programs\\python\\python38-32\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[0mIncompleteRead\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdetect\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \"\"\"\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "sns.set_style('dark')\n",
    "\n",
    "\n",
    "#obtaining the data\n",
    "df = pd.read_csv(\"https://www.dropbox.com/s/b44o3t3ehmnx2b7/creditcard.csv?dl=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec44469c",
   "metadata": {},
   "source": [
    "The great practice is to check the first five lines and the last five lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf252923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking first five lines\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e60eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking last five lines\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba31f5",
   "metadata": {},
   "source": [
    "Something good in these results above is that we can't see any missing value. So, let's go to confirm this hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4226faa",
   "metadata": {},
   "source": [
    "## Are there any missing values in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb02bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing values, primitive types and memory. \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096495a4",
   "metadata": {},
   "source": [
    "We were right, there are no missing values no in this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff92bff",
   "metadata": {},
   "source": [
    "## Basics Statistics\n",
    "\n",
    "A good practice in the beginning of the analysis is to check basics statistics about the numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking basics statistics\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17113e",
   "metadata": {},
   "source": [
    "It's so hard to understand this result because we only have three variables that make sense. However, there is something that we can analyze, this is the **minimum value** for the amount variable.\n",
    "\n",
    "I perceived that the minimum value is zero, but not make sense to make a transaction with the value zero.\n",
    "\n",
    "Thinking about this, I'll analyze this variable better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef2f75",
   "metadata": {},
   "source": [
    "## Understanding Amount Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking Amount variable for non-fraud transactions\n",
    "\n",
    "df.loc[(df.Class == 0) & (df.Amount == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c7deb",
   "metadata": {},
   "source": [
    "We can see that there are many non-fraud transactions with value zero, almost **1.800 transactions**. Although, we don't have much information about why this happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96441d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking Amount variable for frauds transactions\n",
    "\n",
    "df.loc[(df.Class == 1) & (df.Amount == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c558b5c",
   "metadata": {},
   "source": [
    "At fraud transactions, this value is less than non-fraud transactions with only **27 transactions.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e37ec",
   "metadata": {},
   "source": [
    "Still analyzing the amount variable, it is possible to check in the result of describe command that the mean is **88 USD** and the median is **22 USD**, but the maximum value is **25.691,16 USD**. It looks like **an outlier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973c2d5",
   "metadata": {},
   "source": [
    "## Are outliers non-fraud transactions or fraudulent transactions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0604012",
   "metadata": {},
   "source": [
    "So, let's go to analyze the distribution of the amount variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5069ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of Amount variable using histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.hist(df.Time[df.Class == 0], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of Amount variable using histogram\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.hist(df.Time[df.Class == 1], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of Amount variable using boxplot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "non_fraud = df.loc[df.Class == 0].copy()\n",
    "\n",
    "non_fraud.Amount.plot(kind='box', ax=ax, vert=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of Amount variable using boxplot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "frauds = df.loc[df.Class == 1].copy()\n",
    "\n",
    "frauds.Amount.plot(kind='box', ax=ax, vert=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04776521",
   "metadata": {},
   "source": [
    "Just paying attention to the values between **10.000 and 25.000**, they look like outliers. However, I don't make any changes because this dataset is still very **unbalanced.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63524c6c",
   "metadata": {},
   "source": [
    "## Class Variable\n",
    "\n",
    "As was introduced in the scope of the project, the Class variable is very unbalanced. I will check this problem in this topic and how we can solve this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking distribution of the Class variable\n",
    "\n",
    "ax = sns.countplot(x=\"Class\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea48114",
   "metadata": {},
   "outputs": [],
   "source": [
    "frauds_percentage = (len(frauds) / df.shape[0]) * 100\n",
    "\n",
    "print(f'Non-fraud transactions: {len(non_fraud)}')\n",
    "print(f'Frauds transactions: {len(frauds)}')\n",
    "print(f'Frauds percentage: {(frauds_percentage):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc04ddb7",
   "metadata": {},
   "source": [
    "When we are working with credit card fraud, it is normal to have more non-fraud transactions than frauds. \n",
    "\n",
    "However, this problem will prejudice the Machine Learning model. \n",
    "If we train a model using this dataset without correct this problem, the result will be so good with the train data but will be horrible with new data. It happens because the model didn't learn the variability about the dataset, and the model just decorated the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83dd6c",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10f8c0",
   "metadata": {},
   "source": [
    "As mentioned in the problem, the dataset suffered a normalization by the PCA method. However, the Amount and Time variables didn't suffer normalization, and it can be a problem in the future when applying Logistic Regression to predict the output. \n",
    "\n",
    "The dataset is also very unbalanced. In this topic, I will apply undersampling, oversampling, and standardization methods to improve the dataset.\n",
    "\n",
    "The steps: \n",
    "\n",
    "* Split the dataset in train_data and test_data\n",
    "* Undersampling using the Near-Miss method.\n",
    "* Oversampling using the SMOTEEN method.\n",
    "* Standardization using the StandardScaler method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661230fb",
   "metadata": {},
   "source": [
    "### Separating Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar variáveis entre X e y\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# dividir o dataset entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9a0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c936ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
